{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLLToBUXEhnro/mzCt7oJ9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e2736a733f01423382a074eb3cb2ed9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ced804aa41f48a4902c8290aea1ef24",
              "IPY_MODEL_038d4d4e35b34509a8895ed99f8b7bbb",
              "IPY_MODEL_cc7b5d15ceec4c389cfa4fe717f13e0d"
            ],
            "layout": "IPY_MODEL_fc1a9405b52b48f6995badd9d9524386"
          }
        },
        "4ced804aa41f48a4902c8290aea1ef24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286395902e104061b386ea16c283b1ee",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ed4a51a2c1e84d48aac72998ec87a159",
            "value": "SyntheticMass_Data_Hack_ArangoDB.zip:â€‡100%"
          }
        },
        "038d4d4e35b34509a8895ed99f8b7bbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49fa3062c18644bf94faf5c422086176",
            "max": 2414895589,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b573c07b35544b2e82fd22a2f4595b48",
            "value": 2414895589
          }
        },
        "cc7b5d15ceec4c389cfa4fe717f13e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da6901289f7b463d8db19c805b7d205c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1ffcf384751648819d22fd82929ef310",
            "value": "â€‡2.41G/2.41Gâ€‡[00:56&lt;00:00,â€‡32.2MB/s]"
          }
        },
        "fc1a9405b52b48f6995badd9d9524386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286395902e104061b386ea16c283b1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4a51a2c1e84d48aac72998ec87a159": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49fa3062c18644bf94faf5c422086176": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b573c07b35544b2e82fd22a2f4595b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da6901289f7b463d8db19c805b7d205c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ffcf384751648819d22fd82929ef310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajitonelsonn/H_ArngoDB/blob/main/H_ArangoDB_Download_Extract_and_Merge_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ¥ SyntheticMass Health Data Processing Pipeline\n",
        "\n",
        "## A Comprehensive Data Engineering Project for Healthcare Analytics\n",
        "\n",
        "---\n",
        "\n",
        "### ðŸ“Š Project Components:\n",
        "1. **Data Download**: Box dataset retrieval\n",
        "2. **Archive Extraction**: Processing nested archives\n",
        "3. **CSV Management**: Merging and organizing data\n",
        "4. **Data Analysis**: Sample visualization and statistics\n",
        "5. **Distribution**: ZIP creation and Hugging Face upload"
      ],
      "metadata": {
        "id": "x34jvaYezK6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**âš  Important:** This notebook is run using **High RAM** on Google Colab."
      ],
      "metadata": {
        "id": "ZV5vGFJ4ZAgX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Dataset Download Code"
      ],
      "metadata": {
        "id": "_XwT5FBcwcPQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "## Import Section\n",
        "All necessary Python libraries are imported for handling downloads, file compression, and file system operations.\n",
        "\n",
        "## Main Function Overview\n",
        "The `download_box_data()` function is designed to:\n",
        "- Download a compressed dataset from Box\n",
        "- Extract the contents\n",
        "- Manage the files locally\n",
        "- Handle any potential errors\n",
        "\n",
        "## URL and Directory Setup\n",
        "Creates a new directory for downloaded data and defines the Box URL where the dataset is stored.\n",
        "\n",
        "## Download Process\n",
        "Downloads the file in chunks to manage memory efficiently, especially for large files. The streaming approach prevents loading the entire file into memory at once.\n",
        "\n",
        "## File Saving\n",
        "Saves the downloaded compressed file to disk, writing it chunk by chunk to ensure stable handling of large files.\n",
        "\n",
        "## Extraction Logic\n",
        "Has two extraction methods:\n",
        "- Handles TAR.GZ files using the tarfile module\n",
        "- Falls back to regular GZIP extraction if not a TAR file\n",
        "- Shows the size of extracted files\n",
        "\n",
        "## File Cleanup\n",
        "Gives the user control over keeping or deleting the compressed file after extraction is complete.\n",
        "\n",
        "## Error Handling\n",
        "Implements comprehensive error handling for:\n",
        "- Download failures\n",
        "- File processing issues\n",
        "- General exceptions\n",
        "\n",
        "## Execution\n",
        "Final step that runs the download function and stores the resulting file path for further use."
      ],
      "metadata": {
        "id": "jtSGdlsm0fcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "yKf6NFME029k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBuwnfa9VlfU",
        "outputId": "1ff19630-3bb3-4738-fb7f-0ba965c5033b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading Box dataset...\n",
            "Downloading file...\n",
            "Downloaded file size: 21304.18 MB\n",
            "Detected tar.gz format, extracting...\n",
            "\n",
            "Extracted files:\n",
            "- synthea_1m_fhir_3_0_May_24: 0.00 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_10_20170528T030916.tar.gz: 1816.68 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_11_20170528T113605.tar.gz: 1815.63 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_12_20170528T195303.tar.gz: 1814.30 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_1_20170524T232103.tar.gz: 1815.34 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_2_20170525T073836.tar.gz: 1817.33 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_3_20170525T161555.tar.gz: 1811.70 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_4_20170526T004637.tar.gz: 1817.53 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_5_20170526T091439.tar.gz: 1814.23 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_6_20170526T173337.tar.gz: 1814.72 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_7_20170527T015508.tar.gz: 1810.01 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_8_20170527T102552.tar.gz: 1813.36 MB\n",
            "- synthea_1m_fhir_3_0_May_24/output_9_20170527T185007.tar.gz: 1817.47 MB\n",
            "\n",
            "Keep compressed file? (y/n): y\n"
          ]
        }
      ],
      "source": [
        "# Download Box Dataset\n",
        "import requests\n",
        "import gzip\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "import tarfile\n",
        "\n",
        "print(\"Downloading Box dataset...\")\n",
        "\n",
        "def download_box_data():\n",
        "    \"\"\"Downloads and extracts gzipped data from Box\"\"\"\n",
        "    url = \"https://mitre.box.com/shared/static/3bo45m48ocpzp8fc0tp005vax7l93xji.gz\"\n",
        "    output_dir = Path('downloaded_data')\n",
        "    output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # Download the file\n",
        "        print(\"Downloading file...\")\n",
        "        response = requests.get(url, stream=True)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Save the compressed file\n",
        "        gz_path = output_dir / 'data.tar.gz'\n",
        "        with open(gz_path, 'wb') as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "\n",
        "        print(f\"Downloaded file size: {gz_path.stat().st_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "        # Check if it's a tar.gz file\n",
        "        if tarfile.is_tarfile(gz_path):\n",
        "            print(\"Detected tar.gz format, extracting...\")\n",
        "            with tarfile.open(gz_path, 'r:gz') as tar:\n",
        "                tar.extractall(path=output_dir)\n",
        "                extracted_files = tar.getnames()\n",
        "        else:\n",
        "            # Try regular gzip extraction\n",
        "            print(\"Attempting gzip extraction...\")\n",
        "            output_path = output_dir / 'extracted_data'\n",
        "            with gzip.open(gz_path, 'rb') as f_in:\n",
        "                with open(output_path, 'wb') as f_out:\n",
        "                    shutil.copyfileobj(f_in, f_out)\n",
        "            extracted_files = [output_path]\n",
        "\n",
        "        print(\"\\nExtracted files:\")\n",
        "        for file in extracted_files:\n",
        "            file_path = output_dir / Path(file)\n",
        "            if file_path.exists():\n",
        "                print(f\"- {file}: {file_path.stat().st_size / (1024*1024):.2f} MB\")\n",
        "\n",
        "        # Ask before cleaning up\n",
        "        keep_gz = input(\"\\nKeep compressed file? (y/n): \").lower().strip() == 'y'\n",
        "        if not keep_gz:\n",
        "            gz_path.unlink()\n",
        "            print(\"Compressed file removed\")\n",
        "\n",
        "        return output_dir\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Download failed: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file: {str(e)}\")\n",
        "        print(\"Full error details:\", e)\n",
        "\n",
        "    return None\n",
        "\n",
        "# Execute download\n",
        "downloaded_path = download_box_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Nested Archive Extraction Code"
      ],
      "metadata": {
        "id": "83HGTCNfwt5l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "## Function Purpose\n",
        "The `extract_nested_archives` function searches through a directory for tar.gz files, extracts them, and collects all CSV files into a separate directory.\n",
        "\n",
        "## Input Parameters\n",
        "- `base_dir`: Source directory containing the archives (default path for downloaded Synthea data)\n",
        "- `output_dir`: Destination directory for extracted CSV files\n",
        "\n",
        "## Directory Setup\n",
        "Creates an output directory to store all discovered CSV files in an organized structure.\n",
        "\n",
        "## Main Process Flow\n",
        "1. **Archive Discovery**: Searches for all tar.gz files in the base directory\n",
        "2. **Temporary Processing**: Creates a temp directory for each archive during extraction\n",
        "3. **File Extraction**: Extracts archives one by one using tarfile module\n",
        "4. **CSV Collection**:\n",
        "   - Finds all CSV files in extracted content\n",
        "   - Maintains original directory structure\n",
        "   - Copies only new or modified files\n",
        "\n",
        "## File Organization\n",
        "- Preserves relative paths from source\n",
        "- Creates necessary subdirectories automatically\n",
        "- Avoids duplicate copies of identical files\n",
        "\n",
        "## Cleanup Process\n",
        "- Removes temporary directories after processing\n",
        "- Maintains clean workspace during extraction\n",
        "\n",
        "## Summary Generation\n",
        "- Groups CSV files by type (based on filename)\n",
        "- Shows first 3 examples of each type\n",
        "- Provides count of remaining files\n",
        "- Creates organized overview of extracted data\n",
        "\n",
        "## Error Handling\n",
        "Includes try-catch blocks to:\n",
        "- Handle extraction errors gracefully\n",
        "- Continue processing remaining files if one fails\n",
        "- Provide error feedback for troubleshooting"
      ],
      "metadata": {
        "id": "L4hVNSvB0edm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "VNQZhkqL06uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Nested Archives and Find CSVs\n",
        "import tarfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "def extract_nested_archives(base_dir='downloaded_data/synthea_1m_fhir_3_0_May_24',\n",
        "                          output_dir='extracted_csvs'):\n",
        "    \"\"\"\n",
        "    Extract nested tar.gz files and collect CSV files\n",
        "    \"\"\"\n",
        "    base_path = Path(base_dir)\n",
        "    output_path = Path(output_dir)\n",
        "\n",
        "    # Create output directory\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "\n",
        "    print(\"Starting extraction of nested archives...\")\n",
        "\n",
        "    # Track discovered CSV files\n",
        "    csv_files = []\n",
        "\n",
        "    # Process each tar.gz file in the base directory\n",
        "    for tar_file in base_path.glob('*.tar.gz'):\n",
        "        print(f\"\\nProcessing {tar_file.name}...\")\n",
        "\n",
        "        # Create temporary directory for this archive\n",
        "        temp_dir = base_path / f\"temp_{tar_file.stem}\"\n",
        "        temp_dir.mkdir(exist_ok=True)\n",
        "\n",
        "        try:\n",
        "            # Extract the tar.gz file\n",
        "            with tarfile.open(tar_file, 'r:gz') as tar:\n",
        "                tar.extractall(path=temp_dir)\n",
        "\n",
        "            # Find and copy CSV files\n",
        "            for csv_file in temp_dir.rglob('*.csv'):\n",
        "                # Get relative path components\n",
        "                rel_path = csv_file.relative_to(temp_dir)\n",
        "\n",
        "                # Create destination path\n",
        "                dest_path = output_path / rel_path\n",
        "                dest_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "                # Copy file if it doesn't exist or is different\n",
        "                if not dest_path.exists() or csv_file.stat().st_size != dest_path.stat().st_size:\n",
        "                    shutil.copy2(csv_file, dest_path)\n",
        "                    print(f\"Copied: {rel_path}\")\n",
        "                    csv_files.append(dest_path)\n",
        "\n",
        "            # Clean up temporary directory\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {tar_file.name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "    # Print summary\n",
        "    print(\"\\nExtraction complete!\")\n",
        "    print(f\"Found {len(csv_files)} unique CSV files:\")\n",
        "\n",
        "    # Group and display CSV files by type\n",
        "    csv_by_type = {}\n",
        "    for csv_file in csv_files:\n",
        "        file_type = csv_file.stem.split('_')[0]\n",
        "        if file_type not in csv_by_type:\n",
        "            csv_by_type[file_type] = []\n",
        "        csv_by_type[file_type].append(csv_file)\n",
        "\n",
        "    for file_type, files in csv_by_type.items():\n",
        "        print(f\"\\n{file_type.capitalize()} files ({len(files)}):\")\n",
        "        for file in files[:3]:  # Show first 3 examples\n",
        "            print(f\"- {file.name}\")\n",
        "        if len(files) > 3:\n",
        "            print(f\"  ... and {len(files) - 3} more\")\n",
        "\n",
        "    return csv_files\n",
        "\n",
        "# Execute extraction\n",
        "csv_files = extract_nested_archives()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wlKQszb5P7",
        "outputId": "007077db-42ff-4c70-e631-612d05f4c4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting extraction of nested archives...\n",
            "\n",
            "Processing output_8_20170527T102552.tar.gz...\n",
            "Copied: output_8/csv/allergies.csv\n",
            "Copied: output_8/csv/careplans.csv\n",
            "Copied: output_8/csv/immunizations.csv\n",
            "Copied: output_8/csv/observations.csv\n",
            "Copied: output_8/csv/encounters.csv\n",
            "Copied: output_8/csv/medications.csv\n",
            "Copied: output_8/csv/procedures.csv\n",
            "Copied: output_8/csv/patients.csv\n",
            "Copied: output_8/csv/conditions.csv\n",
            "\n",
            "Processing output_10_20170528T030916.tar.gz...\n",
            "Copied: output_10/csv/allergies.csv\n",
            "Copied: output_10/csv/careplans.csv\n",
            "Copied: output_10/csv/immunizations.csv\n",
            "Copied: output_10/csv/observations.csv\n",
            "Copied: output_10/csv/encounters.csv\n",
            "Copied: output_10/csv/medications.csv\n",
            "Copied: output_10/csv/procedures.csv\n",
            "Copied: output_10/csv/patients.csv\n",
            "Copied: output_10/csv/conditions.csv\n",
            "\n",
            "Processing output_2_20170525T073836.tar.gz...\n",
            "Copied: output_2/csv/allergies.csv\n",
            "Copied: output_2/csv/careplans.csv\n",
            "Copied: output_2/csv/immunizations.csv\n",
            "Copied: output_2/csv/observations.csv\n",
            "Copied: output_2/csv/encounters.csv\n",
            "Copied: output_2/csv/medications.csv\n",
            "Copied: output_2/csv/procedures.csv\n",
            "Copied: output_2/csv/patients.csv\n",
            "Copied: output_2/csv/conditions.csv\n",
            "\n",
            "Processing output_3_20170525T161555.tar.gz...\n",
            "Copied: output_3/csv/allergies.csv\n",
            "Copied: output_3/csv/careplans.csv\n",
            "Copied: output_3/csv/immunizations.csv\n",
            "Copied: output_3/csv/observations.csv\n",
            "Copied: output_3/csv/encounters.csv\n",
            "Copied: output_3/csv/medications.csv\n",
            "Copied: output_3/csv/procedures.csv\n",
            "Copied: output_3/csv/patients.csv\n",
            "Copied: output_3/csv/conditions.csv\n",
            "\n",
            "Processing output_12_20170528T195303.tar.gz...\n",
            "Copied: output_12/csv/allergies.csv\n",
            "Copied: output_12/csv/careplans.csv\n",
            "Copied: output_12/csv/immunizations.csv\n",
            "Copied: output_12/csv/observations.csv\n",
            "Copied: output_12/csv/encounters.csv\n",
            "Copied: output_12/csv/medications.csv\n",
            "Copied: output_12/csv/procedures.csv\n",
            "Copied: output_12/csv/patients.csv\n",
            "Copied: output_12/csv/conditions.csv\n",
            "\n",
            "Processing output_1_20170524T232103.tar.gz...\n",
            "Copied: output_1/csv/allergies.csv\n",
            "Copied: output_1/csv/careplans.csv\n",
            "Copied: output_1/csv/immunizations.csv\n",
            "Copied: output_1/csv/observations.csv\n",
            "Copied: output_1/csv/encounters.csv\n",
            "Copied: output_1/csv/medications.csv\n",
            "Copied: output_1/csv/procedures.csv\n",
            "Copied: output_1/csv/patients.csv\n",
            "Copied: output_1/csv/conditions.csv\n",
            "\n",
            "Processing output_9_20170527T185007.tar.gz...\n",
            "Copied: output_9/csv/allergies.csv\n",
            "Copied: output_9/csv/careplans.csv\n",
            "Copied: output_9/csv/immunizations.csv\n",
            "Copied: output_9/csv/observations.csv\n",
            "Copied: output_9/csv/encounters.csv\n",
            "Copied: output_9/csv/medications.csv\n",
            "Copied: output_9/csv/procedures.csv\n",
            "Copied: output_9/csv/patients.csv\n",
            "Copied: output_9/csv/conditions.csv\n",
            "\n",
            "Processing output_7_20170527T015508.tar.gz...\n",
            "Copied: output_7/csv/allergies.csv\n",
            "Copied: output_7/csv/careplans.csv\n",
            "Copied: output_7/csv/immunizations.csv\n",
            "Copied: output_7/csv/observations.csv\n",
            "Copied: output_7/csv/encounters.csv\n",
            "Copied: output_7/csv/medications.csv\n",
            "Copied: output_7/csv/procedures.csv\n",
            "Copied: output_7/csv/patients.csv\n",
            "Copied: output_7/csv/conditions.csv\n",
            "\n",
            "Processing output_6_20170526T173337.tar.gz...\n",
            "Copied: output_6/csv/allergies.csv\n",
            "Copied: output_6/csv/careplans.csv\n",
            "Copied: output_6/csv/immunizations.csv\n",
            "Copied: output_6/csv/observations.csv\n",
            "Copied: output_6/csv/encounters.csv\n",
            "Copied: output_6/csv/medications.csv\n",
            "Copied: output_6/csv/procedures.csv\n",
            "Copied: output_6/csv/patients.csv\n",
            "Copied: output_6/csv/conditions.csv\n",
            "\n",
            "Processing output_5_20170526T091439.tar.gz...\n",
            "Copied: output_5/csv/allergies.csv\n",
            "Copied: output_5/csv/careplans.csv\n",
            "Copied: output_5/csv/immunizations.csv\n",
            "Copied: output_5/csv/observations.csv\n",
            "Copied: output_5/csv/encounters.csv\n",
            "Copied: output_5/csv/medications.csv\n",
            "Copied: output_5/csv/procedures.csv\n",
            "Copied: output_5/csv/patients.csv\n",
            "Copied: output_5/csv/conditions.csv\n",
            "\n",
            "Processing output_4_20170526T004637.tar.gz...\n",
            "Copied: output_4/csv/allergies.csv\n",
            "Copied: output_4/csv/careplans.csv\n",
            "Copied: output_4/csv/immunizations.csv\n",
            "Copied: output_4/csv/observations.csv\n",
            "Copied: output_4/csv/encounters.csv\n",
            "Copied: output_4/csv/medications.csv\n",
            "Copied: output_4/csv/procedures.csv\n",
            "Copied: output_4/csv/patients.csv\n",
            "Copied: output_4/csv/conditions.csv\n",
            "\n",
            "Processing output_11_20170528T113605.tar.gz...\n",
            "Copied: output_11/csv/allergies.csv\n",
            "Copied: output_11/csv/careplans.csv\n",
            "Copied: output_11/csv/immunizations.csv\n",
            "Copied: output_11/csv/observations.csv\n",
            "Copied: output_11/csv/encounters.csv\n",
            "Copied: output_11/csv/medications.csv\n",
            "Copied: output_11/csv/procedures.csv\n",
            "Copied: output_11/csv/patients.csv\n",
            "Copied: output_11/csv/conditions.csv\n",
            "\n",
            "Extraction complete!\n",
            "Found 108 unique CSV files:\n",
            "\n",
            "Allergies files (12):\n",
            "- allergies.csv\n",
            "- allergies.csv\n",
            "- allergies.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Careplans files (12):\n",
            "- careplans.csv\n",
            "- careplans.csv\n",
            "- careplans.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Immunizations files (12):\n",
            "- immunizations.csv\n",
            "- immunizations.csv\n",
            "- immunizations.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Observations files (12):\n",
            "- observations.csv\n",
            "- observations.csv\n",
            "- observations.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Encounters files (12):\n",
            "- encounters.csv\n",
            "- encounters.csv\n",
            "- encounters.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Medications files (12):\n",
            "- medications.csv\n",
            "- medications.csv\n",
            "- medications.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Procedures files (12):\n",
            "- procedures.csv\n",
            "- procedures.csv\n",
            "- procedures.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Patients files (12):\n",
            "- patients.csv\n",
            "- patients.csv\n",
            "- patients.csv\n",
            "  ... and 9 more\n",
            "\n",
            "Conditions files (12):\n",
            "- conditions.csv\n",
            "- conditions.csv\n",
            "- conditions.csv\n",
            "  ... and 9 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.**CSV** File Merging Code"
      ],
      "metadata": {
        "id": "VnKaQfZHw0B8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "## Function Purpose\n",
        "The `merge_csv_files` function combines multiple CSV files with the same name from different directories into single consolidated files.\n",
        "\n",
        "## Input Parameters\n",
        "- `source_dir`: Directory containing the CSV files (default: 'extracted_csvs')\n",
        "- `output_dir`: Directory where merged files will be saved (default: 'final_merge')\n",
        "\n",
        "## Initial Setup\n",
        "- Creates output directory\n",
        "- Finds all unique CSV filenames across all subdirectories\n",
        "\n",
        "## CSV Processing Flow\n",
        "1. **File Discovery**:\n",
        "   - Identifies all instances of each unique CSV filename\n",
        "   - Creates consistent column structure from first file\n",
        "\n",
        "2. **Data Reading**:\n",
        "   - Reads each CSV file maintaining original column structure\n",
        "   - Tracks total row count\n",
        "   - Reports successful reads and any errors\n",
        "\n",
        "3. **Merging Process**:\n",
        "   - Combines all dataframes using pandas concat\n",
        "   - Preserves data integrity with ignore_index\n",
        "   - Maintains original column structure\n",
        "\n",
        "## File Output\n",
        "- Saves merged files to output directory\n",
        "- Preserves original filename\n",
        "- Reports file statistics:\n",
        "  - Number of files merged\n",
        "  - Total row count\n",
        "  - Final file size in MB\n",
        "\n",
        "## Error Handling\n",
        "- Per-file error catching\n",
        "- Continues processing if individual files fail\n",
        "- Reports specific errors for troubleshooting\n",
        "- Ensures partial success if some files can't be processed\n",
        "\n",
        "## Progress Reporting\n",
        "- Shows current file being processed\n",
        "- Reports successful file reads\n",
        "- Provides merge statistics\n",
        "- Shows final file sizes"
      ],
      "metadata": {
        "id": "ThuhANGM0dCk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "E_gQWBot09ap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "def merge_csv_files(source_dir='extracted_csvs', output_dir='final_merge'):\n",
        "    \"\"\"\n",
        "    Merge CSV files with the same name from different directories and save to output directory\n",
        "    \"\"\"\n",
        "    # Create output directory if it doesn't exist\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Get unique CSV file names\n",
        "    unique_csv_names = set()\n",
        "    for csv_file in Path(source_dir).rglob('*.csv'):\n",
        "        unique_csv_names.add(csv_file.name)\n",
        "\n",
        "    print(\"Starting CSV merging process...\")\n",
        "\n",
        "    # Process each unique CSV name\n",
        "    for csv_name in unique_csv_names:\n",
        "        print(f\"\\nProcessing {csv_name}...\")\n",
        "\n",
        "        try:\n",
        "            # Find all files with this name\n",
        "            csv_files = list(Path(source_dir).rglob(f'**/{csv_name}'))\n",
        "\n",
        "            # First read the header of the first file to get column structure\n",
        "            first_df = pd.read_csv(csv_files[0], nrows=0)\n",
        "            columns = first_df.columns.tolist()\n",
        "\n",
        "            # Read and concatenate all matching CSV files\n",
        "            dfs = []\n",
        "            total_rows = 0\n",
        "\n",
        "            for file in csv_files:\n",
        "                try:\n",
        "                    # Read CSV with only the columns from the first file\n",
        "                    df = pd.read_csv(file, usecols=columns)\n",
        "                    total_rows += len(df)\n",
        "                    dfs.append(df)\n",
        "                    print(f\"Successfully read {file}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error reading {file}: {str(e)}\")\n",
        "                    continue\n",
        "\n",
        "            if dfs:\n",
        "                # Merge all dataframes\n",
        "                merged_df = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "                # Save merged file\n",
        "                output_file = output_path / csv_name\n",
        "                merged_df.to_csv(output_file, index=False)\n",
        "\n",
        "                # Get file size in MB\n",
        "                file_size = output_file.stat().st_size / (1024 * 1024)  # Convert bytes to MB\n",
        "\n",
        "                print(f\"Merged {len(dfs)} files into {csv_name}\")\n",
        "                print(f\"Total rows: {total_rows:,}\")\n",
        "                print(f\"Final file size: {file_size:.2f} MB\")\n",
        "            else:\n",
        "                print(f\"No files were successfully processed for {csv_name}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {csv_name}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "# Execute the merge\n",
        "merge_csv_files()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCVn2TtJzSoP",
        "outputId": "324fe220-8dac-445a-909a-3e640a89e1de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting CSV merging process...\n",
            "\n",
            "Processing medications.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_11/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_9/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_7/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_4/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_10/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_8/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_12/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_2/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_5/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_1/csv/medications.csv\n",
            "Successfully read extracted_csvs/output_3/csv/medications.csv\n",
            "Merged 12 files into medications.csv\n",
            "Total rows: 4,781,956\n",
            "Final file size: 747.25 MB\n",
            "\n",
            "Processing immunizations.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_11/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_9/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_7/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_4/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_10/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_8/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_12/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_2/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_5/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_1/csv/immunizations.csv\n",
            "Successfully read extracted_csvs/output_3/csv/immunizations.csv\n",
            "Merged 12 files into immunizations.csv\n",
            "Total rows: 10,412,118\n",
            "Final file size: 1253.53 MB\n",
            "\n",
            "Processing conditions.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_11/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_9/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_7/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_4/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_10/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_8/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_12/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_2/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_5/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_1/csv/conditions.csv\n",
            "Successfully read extracted_csvs/output_3/csv/conditions.csv\n",
            "Merged 12 files into conditions.csv\n",
            "Total rows: 5,809,954\n",
            "Final file size: 700.92 MB\n",
            "\n",
            "Processing encounters.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_11/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_9/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_7/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_4/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_10/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_8/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_12/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_2/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_5/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_1/csv/encounters.csv\n",
            "Successfully read extracted_csvs/output_3/csv/encounters.csv\n",
            "Merged 12 files into encounters.csv\n",
            "Total rows: 15,109,427\n",
            "Final file size: 1855.81 MB\n",
            "\n",
            "Processing observations.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_11/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_9/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_7/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_4/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_10/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_8/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_12/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_2/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_5/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_1/csv/observations.csv\n",
            "Successfully read extracted_csvs/output_3/csv/observations.csv\n",
            "Merged 12 files into observations.csv\n",
            "Total rows: 64,654,706\n",
            "Final file size: 7543.60 MB\n",
            "\n",
            "Processing patients.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_11/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_9/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_7/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_4/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_10/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_8/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_12/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_2/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_5/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_1/csv/patients.csv\n",
            "Successfully read extracted_csvs/output_3/csv/patients.csv\n",
            "Merged 12 files into patients.csv\n",
            "Total rows: 1,594,711\n",
            "Final file size: 283.73 MB\n",
            "\n",
            "Processing procedures.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_11/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_9/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_7/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_4/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_10/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_8/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_12/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_2/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_5/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_1/csv/procedures.csv\n",
            "Successfully read extracted_csvs/output_3/csv/procedures.csv\n",
            "Merged 12 files into procedures.csv\n",
            "Total rows: 7,502,018\n",
            "Final file size: 1006.89 MB\n",
            "\n",
            "Processing careplans.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_11/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_9/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_7/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_4/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_10/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_8/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_12/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_2/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_5/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_1/csv/careplans.csv\n",
            "Successfully read extracted_csvs/output_3/csv/careplans.csv\n",
            "Merged 12 files into careplans.csv\n",
            "Total rows: 9,558,659\n",
            "Final file size: 1750.05 MB\n",
            "\n",
            "Processing allergies.csv...\n",
            "Successfully read extracted_csvs/output_6/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_11/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_9/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_7/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_4/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_10/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_8/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_12/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_2/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_5/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_1/csv/allergies.csv\n",
            "Successfully read extracted_csvs/output_3/csv/allergies.csv\n",
            "Merged 12 files into allergies.csv\n",
            "Total rows: 624,611\n",
            "Final file size: 69.61 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Data Sample Display Code"
      ],
      "metadata": {
        "id": "moF0XY6eeCn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "\n",
        "## Function Purpose\n",
        "The `show_merged_data_samples` function provides a comprehensive overview of each merged CSV file, showing key statistics and sample data.\n",
        "\n",
        "## Input Parameters\n",
        "- `merged_dir`: Directory containing merged CSV files (default: 'final_merge')\n",
        "- `num_samples`: Number of sample rows to display (default: 5)\n",
        "\n",
        "## Data Overview Process\n",
        "1. **File Discovery**:\n",
        "   - Locates all CSV files in merged directory\n",
        "   - Processes each file individually\n",
        "\n",
        "2. **Basic Information Display**:\n",
        "   - Shows filename\n",
        "   - Reports total row count\n",
        "   - Lists all column names\n",
        "   - Displays column count\n",
        "\n",
        "3. **Sample Data Display**:\n",
        "   - Shows first few rows of data\n",
        "   - Uses specified sample size\n",
        "   - Maintains readable format\n",
        "\n",
        "4. **Statistical Analysis**:\n",
        "   - Generates descriptive statistics\n",
        "   - Focuses on numeric columns\n",
        "   - Rounds values for readability\n",
        "   - Includes:\n",
        "     - Count\n",
        "     - Mean\n",
        "     - Standard deviation\n",
        "     - Min/Max values\n",
        "     - Quartile information\n",
        "\n",
        "## Output Formatting\n",
        "- Uses clear section separators\n",
        "- Organizes information logically\n",
        "- Makes output easily readable\n",
        "- Provides consistent structure across files\n",
        "\n",
        "## Visual Organization\n",
        "- Uses separator lines for clarity\n",
        "- Groups related information together\n",
        "- Maintains consistent spacing\n",
        "- Creates clear visual hierarchy"
      ],
      "metadata": {
        "id": "0NT8vWT10VKr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "KTzdtnBl0_RD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_merged_data_samples(merged_dir='final_merge', num_samples=5):\n",
        "    \"\"\"\n",
        "    Display sample data from each merged CSV file\n",
        "    \"\"\"\n",
        "    merged_path = Path(merged_dir)\n",
        "\n",
        "    # Get all CSV files in the merged directory\n",
        "    merged_files = list(merged_path.glob('*.csv'))\n",
        "\n",
        "    for file in merged_files:\n",
        "        print(f\"\\n{'='*80}\")\n",
        "        print(f\"File: {file.name}\")\n",
        "        print(f\"{'='*80}\")\n",
        "\n",
        "        # Read the CSV file\n",
        "        df = pd.read_csv(file)\n",
        "\n",
        "        # Display basic information\n",
        "        print(\"\\nDataset Info:\")\n",
        "        print(f\"Total Rows: {len(df):,}\")\n",
        "        print(f\"Total Columns: {len(df.columns):,}\")\n",
        "        print(\"\\nColumns:\", ', '.join(df.columns))\n",
        "\n",
        "        # Display sample data\n",
        "        print(f\"\\nFirst {num_samples} rows:\")\n",
        "        print(df.head(num_samples))\n",
        "\n",
        "        # Display basic statistics for numeric columns\n",
        "        print(\"\\nNumeric Columns Statistics:\")\n",
        "        print(df.describe().round(2))\n",
        "\n",
        "# Execute the function\n",
        "show_merged_data_samples()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_hO8TLtKz2U",
        "outputId": "968e136a-209b-412a-d28a-2cf928d92d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "File: allergies.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 624,611\n",
            "Total Columns: 6\n",
            "\n",
            "Columns: START, STOP, PATIENT, ENCOUNTER, CODE, DESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "        START STOP                               PATIENT  \\\n",
            "0  1990-10-01  NaN  6d1aa8c5-c16e-488c-9542-c08b016a069a   \n",
            "1  1990-10-01  NaN  6d1aa8c5-c16e-488c-9542-c08b016a069a   \n",
            "2  1963-01-05  NaN  aca17de8-b17d-4db0-91c5-8dc3211df286   \n",
            "3  1981-09-04  NaN  058388d9-e0c2-49ae-8994-a9db47205c8b   \n",
            "4  1981-09-04  NaN  058388d9-e0c2-49ae-8994-a9db47205c8b   \n",
            "\n",
            "                              ENCOUNTER       CODE              DESCRIPTION  \n",
            "0  338c5a79-5ca2-40e8-8503-c511b9a9315f  417532002          Allergy to fish  \n",
            "1  338c5a79-5ca2-40e8-8503-c511b9a9315f  232347008  Dander (animal) allergy  \n",
            "2  9b65787f-cf76-4299-84ac-815e03b1ba06  300913006        Shellfish allergy  \n",
            "3  e1029f45-c057-42c6-a393-20cbc2726620  232350006  House dust mite allergy  \n",
            "4  e1029f45-c057-42c6-a393-20cbc2726620  300916003            Latex allergy  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "               CODE\n",
            "count  6.246110e+05\n",
            "mean   3.221781e+08\n",
            "std    1.244106e+08\n",
            "min    9.193000e+07\n",
            "25%    2.323470e+08\n",
            "50%    4.175320e+08\n",
            "75%    4.194740e+08\n",
            "max    7.140350e+08\n",
            "\n",
            "================================================================================\n",
            "File: careplans.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 9,558,659\n",
            "Total Columns: 9\n",
            "\n",
            "Columns: ID, START, STOP, PATIENT, ENCOUNTER, CODE, DESCRIPTION, REASONCODE, REASONDESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "                                     ID       START        STOP  \\\n",
            "0  f8407e0f-a655-4715-9231-330a55ae18fc  2009-11-14  2010-09-28   \n",
            "1  f8407e0f-a655-4715-9231-330a55ae18fc  2009-11-14  2010-09-28   \n",
            "2  f8407e0f-a655-4715-9231-330a55ae18fc  2009-11-14  2010-09-28   \n",
            "3  366cddd8-ed88-4f74-9012-ed30d599f6bb  2014-10-30  2015-09-18   \n",
            "4  366cddd8-ed88-4f74-9012-ed30d599f6bb  2014-10-30  2015-09-18   \n",
            "\n",
            "                                PATIENT                             ENCOUNTER  \\\n",
            "0  15558d47-974b-43a1-afff-8ad464e291a8  cc57c1bb-a419-4eed-ba72-db1eb5fcf1fc   \n",
            "1  15558d47-974b-43a1-afff-8ad464e291a8  cc57c1bb-a419-4eed-ba72-db1eb5fcf1fc   \n",
            "2  15558d47-974b-43a1-afff-8ad464e291a8  cc57c1bb-a419-4eed-ba72-db1eb5fcf1fc   \n",
            "3  15558d47-974b-43a1-afff-8ad464e291a8  e3be4b38-e90e-4e2e-b517-0ba506e11e89   \n",
            "4  15558d47-974b-43a1-afff-8ad464e291a8  e3be4b38-e90e-4e2e-b517-0ba506e11e89   \n",
            "\n",
            "        CODE                            DESCRIPTION  REASONCODE  \\\n",
            "0   53950000                    Respiratory therapy  10509002.0   \n",
            "1  304510005       Recommendation to avoid exercise  10509002.0   \n",
            "2  371605008  Deep breathing and coughing exercises  10509002.0   \n",
            "3   53950000                    Respiratory therapy  10509002.0   \n",
            "4  304510005       Recommendation to avoid exercise  10509002.0   \n",
            "\n",
            "             REASONDESCRIPTION  \n",
            "0  Acute bronchitis (disorder)  \n",
            "1  Acute bronchitis (disorder)  \n",
            "2  Acute bronchitis (disorder)  \n",
            "3  Acute bronchitis (disorder)  \n",
            "4  Acute bronchitis (disorder)  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "               CODE    REASONCODE\n",
            "count  9.558659e+06  8.424751e+06\n",
            "mean   5.053640e+13  2.370242e+11\n",
            "std    1.839546e+14  4.001994e+12\n",
            "min    4.090020e+05  1.050900e+07\n",
            "25%    1.606700e+08  1.577700e+07\n",
            "50%    2.290700e+08  5.374101e+07\n",
            "75%    4.127760e+08  1.850860e+08\n",
            "max    8.727810e+14  6.784100e+13\n",
            "\n",
            "================================================================================\n",
            "File: immunizations.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 10,412,118\n",
            "Total Columns: 5\n",
            "\n",
            "Columns: DATE, PATIENT, ENCOUNTER, CODE, DESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "         DATE                               PATIENT  \\\n",
            "0  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "1  2012-01-23  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "2  2012-01-23  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "3  2013-01-11  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "4  2013-12-29  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "\n",
            "                              ENCOUNTER  CODE  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01   140   \n",
            "1  2b769b7d-cd84-4322-98a1-53e521b48338   140   \n",
            "2  2b769b7d-cd84-4322-98a1-53e521b48338   114   \n",
            "3  341df5c5-7614-4108-a7f1-fa2e577a4df5   140   \n",
            "4  4206f853-23fd-40b5-bd7b-ca7f6ee25474   140   \n",
            "\n",
            "                                         DESCRIPTION  \n",
            "0  Influenza  seasonal  injectable  preservative ...  \n",
            "1  Influenza  seasonal  injectable  preservative ...  \n",
            "2                                meningococcal MCV4P  \n",
            "3  Influenza  seasonal  injectable  preservative ...  \n",
            "4  Influenza  seasonal  injectable  preservative ...  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "              CODE\n",
            "count  10412118.00\n",
            "mean        110.52\n",
            "std          46.98\n",
            "min           3.00\n",
            "25%         113.00\n",
            "50%         140.00\n",
            "75%         140.00\n",
            "max         140.00\n",
            "\n",
            "================================================================================\n",
            "File: observations.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 64,654,706\n",
            "Total Columns: 7\n",
            "\n",
            "Columns: DATE, PATIENT, ENCOUNTER, CODE, DESCRIPTION, VALUE, UNITS\n",
            "\n",
            "First 5 rows:\n",
            "         DATE                               PATIENT  \\\n",
            "0  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "1  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "2  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "3  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "4  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "\n",
            "                              ENCOUNTER     CODE               DESCRIPTION  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01   8302-2               Body Height   \n",
            "1  e394c6e8-aec3-4764-becd-9f706d0a5c01  29463-7               Body Weight   \n",
            "2  e394c6e8-aec3-4764-becd-9f706d0a5c01  39156-5           Body Mass Index   \n",
            "3  e394c6e8-aec3-4764-becd-9f706d0a5c01   8480-6   Systolic Blood Pressure   \n",
            "4  e394c6e8-aec3-4764-becd-9f706d0a5c01   8462-4  Diastolic Blood Pressure   \n",
            "\n",
            "   VALUE  UNITS  \n",
            "0  171.1     cm  \n",
            "1  54.46     kg  \n",
            "2   18.6  kg/m2  \n",
            "3  112.0   mmHg  \n",
            "4   80.0   mmHg  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "              DATE                               PATIENT  \\\n",
            "count     64654706                              64654706   \n",
            "unique       23997                               1420861   \n",
            "top     2017-03-28  16f61d26-db5e-4843-8552-f6ddfc0fcfde   \n",
            "freq         27570                                   296   \n",
            "\n",
            "                                   ENCOUNTER      CODE  DESCRIPTION     VALUE  \\\n",
            "count                               64654706  64654706     64654706  64485449   \n",
            "unique                               8025584        63           63     19606   \n",
            "top     758ca722-3602-4365-b365-d0a9ad86eacc    8302-2  Body Height       1.0   \n",
            "freq                                     232   7041284      7041284   1940521   \n",
            "\n",
            "           UNITS  \n",
            "count   64485449  \n",
            "unique        17  \n",
            "top        mg/dL  \n",
            "freq    14193616  \n",
            "\n",
            "================================================================================\n",
            "File: encounters.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 15,109,427\n",
            "Total Columns: 7\n",
            "\n",
            "Columns: ID, DATE, PATIENT, CODE, DESCRIPTION, REASONCODE, REASONDESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "                                     ID        DATE  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01  2011-01-26   \n",
            "1  2b769b7d-cd84-4322-98a1-53e521b48338  2012-01-23   \n",
            "2  d626c050-ae52-4c54-90c8-860245026c93  2012-12-28   \n",
            "3  341df5c5-7614-4108-a7f1-fa2e577a4df5  2013-01-11   \n",
            "4  4206f853-23fd-40b5-bd7b-ca7f6ee25474  2013-12-29   \n",
            "\n",
            "                                PATIENT       CODE            DESCRIPTION  \\\n",
            "0  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  170258001   Outpatient Encounter   \n",
            "1  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  170258001   Outpatient Encounter   \n",
            "2  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  185345009  Encounter for symptom   \n",
            "3  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  170258001   Outpatient Encounter   \n",
            "4  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  185349003   Outpatient Encounter   \n",
            "\n",
            "    REASONCODE           REASONDESCRIPTION  \n",
            "0          NaN                         NaN  \n",
            "1          NaN                         NaN  \n",
            "2  444814009.0  Viral sinusitis (disorder)  \n",
            "3          NaN                         NaN  \n",
            "4          NaN                         NaN  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "               CODE    REASONCODE\n",
            "count  1.510943e+07  4.262031e+06\n",
            "mean   2.211696e+08  3.707503e+11\n",
            "std    9.923445e+07  5.561356e+12\n",
            "min    3.248501e+07  1.734006e+06\n",
            "25%    1.853450e+08  7.289200e+07\n",
            "50%    1.853490e+08  7.549800e+07\n",
            "75%    1.853490e+08  3.010110e+08\n",
            "max    6.983140e+08  3.685810e+14\n",
            "\n",
            "================================================================================\n",
            "File: medications.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 4,781,956\n",
            "Total Columns: 8\n",
            "\n",
            "Columns: START, STOP, PATIENT, ENCOUNTER, CODE, DESCRIPTION, REASONCODE, REASONDESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "        START STOP                               PATIENT  \\\n",
            "0  1998-05-07  NaN  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "1  2000-09-28  NaN  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "2  2004-09-10  NaN  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "3  2009-10-25  NaN  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "4  2010-06-02  NaN  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "\n",
            "                              ENCOUNTER    CODE  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01  834060   \n",
            "1  e394c6e8-aec3-4764-becd-9f706d0a5c01  834060   \n",
            "2  e394c6e8-aec3-4764-becd-9f706d0a5c01  834060   \n",
            "3  dfa57629-b9a6-4e58-abde-cb6f71340c0e  748856   \n",
            "4  dfa57629-b9a6-4e58-abde-cb6f71340c0e  834060   \n",
            "\n",
            "                     DESCRIPTION  REASONCODE  \\\n",
            "0  Penicillin V Potassium 250 MG  43878008.0   \n",
            "1  Penicillin V Potassium 250 MG  43878008.0   \n",
            "2  Penicillin V Potassium 250 MG  43878008.0   \n",
            "3                Yaz 28 Day Pack         NaN   \n",
            "4  Penicillin V Potassium 250 MG  43878008.0   \n",
            "\n",
            "                      REASONDESCRIPTION  \n",
            "0  Streptococcal sore throat (disorder)  \n",
            "1  Streptococcal sore throat (disorder)  \n",
            "2  Streptococcal sore throat (disorder)  \n",
            "3                                   NaN  \n",
            "4  Streptococcal sore throat (disorder)  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "             CODE    REASONCODE\n",
            "count  4781956.00  3.363358e+06\n",
            "mean    740887.15  8.330121e+11\n",
            "std     357607.26  7.470014e+12\n",
            "min     106258.00  1.050900e+07\n",
            "25%     564666.00  4.387801e+07\n",
            "50%     824184.00  4.387801e+07\n",
            "75%     849574.00  2.336780e+08\n",
            "max    1856546.00  6.784100e+13\n",
            "\n",
            "================================================================================\n",
            "File: procedures.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 7,502,018\n",
            "Total Columns: 7\n",
            "\n",
            "Columns: DATE, PATIENT, ENCOUNTER, CODE, DESCRIPTION, REASONCODE, REASONDESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "         DATE                               PATIENT  \\\n",
            "0  2011-01-26  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "1  2012-01-23  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "2  2010-06-02  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "3  2010-09-02  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "4  2014-09-06  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "\n",
            "                              ENCOUNTER             CODE  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01  428191000124101   \n",
            "1  2b769b7d-cd84-4322-98a1-53e521b48338  428191000124101   \n",
            "2  dfa57629-b9a6-4e58-abde-cb6f71340c0e        117015009   \n",
            "3  c6e213af-2234-4ebf-8dbe-5be593fd3abc  428191000124101   \n",
            "4  3e1c2e0c-5616-437e-8cb5-345a5d2d27ed  428191000124101   \n",
            "\n",
            "                            DESCRIPTION  REASONCODE  \\\n",
            "0  Documentation of current medications         NaN   \n",
            "1  Documentation of current medications         NaN   \n",
            "2           Throat culture (procedure)   43878008.0   \n",
            "3  Documentation of current medications         NaN   \n",
            "4  Documentation of current medications         NaN   \n",
            "\n",
            "                      REASONDESCRIPTION  \n",
            "0                                   NaN  \n",
            "1                                   NaN  \n",
            "2  Streptococcal sore throat (disorder)  \n",
            "3                                   NaN  \n",
            "4                                   NaN  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "               CODE    REASONCODE\n",
            "count  7.502018e+06  1.897864e+06\n",
            "mean   1.912446e+14  8.317432e+11\n",
            "std    2.245482e+14  8.298113e+12\n",
            "min    1.146600e+07  1.734006e+06\n",
            "25%    1.802560e+08  6.596600e+07\n",
            "50%    3.126810e+08  7.289200e+07\n",
            "75%    4.281910e+14  1.956620e+08\n",
            "max    1.015401e+15  3.685810e+14\n",
            "\n",
            "================================================================================\n",
            "File: patients.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 1,594,711\n",
            "Total Columns: 17\n",
            "\n",
            "Columns: ID, BIRTHDATE, DEATHDATE, SSN, DRIVERS, PASSPORT, PREFIX, FIRST, LAST, SUFFIX, MAIDEN, MARITAL, RACE, ETHNICITY, GENDER, BIRTHPLACE, ADDRESS\n",
            "\n",
            "First 5 rows:\n",
            "                                     ID   BIRTHDATE   DEATHDATE          SSN  \\\n",
            "0  664d2f0c-41d9-4a2e-b92e-82c4b5d201e5  1966-09-12  1976-09-06  999-84-3240   \n",
            "1  addd5d65-4ffb-4ef5-b8c1-51f5d576d8cc  1989-11-02  2009-02-12  999-83-3918   \n",
            "2  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798  1995-10-27         NaN  999-95-3285   \n",
            "3  fef09c76-9855-4a56-a8a8-49085af31cd2  1995-10-18         NaN  999-34-9416   \n",
            "4  15558d47-974b-43a1-afff-8ad464e291a8  1997-08-05         NaN  999-26-6938   \n",
            "\n",
            "     DRIVERS    PASSPORT PREFIX         FIRST        LAST SUFFIX MAIDEN  \\\n",
            "0        NaN         NaN    NaN     Naomie358    Ferry125    NaN    NaN   \n",
            "1  S99949439         NaN    Mr.    Maximus574    Ortiz282    NaN    NaN   \n",
            "2  S99985057  X78987609X    Mr.     Darian470  Kuhlman598    NaN    NaN   \n",
            "3  S99975741  X23238130X    Ms.  Annamarie175  Wiegand497    NaN    NaN   \n",
            "4  S99992594         NaN    Ms.   Cheyanne943    Mayer792    NaN    NaN   \n",
            "\n",
            "  MARITAL   RACE        ETHNICITY GENDER          BIRTHPLACE  \\\n",
            "0     NaN  white          italian      M        Dalton MA US   \n",
            "1     NaN  white            irish      M  West Tisbury MA US   \n",
            "2     NaN  white  french_canadian      M   Bridgewater MA US   \n",
            "3     NaN  white            irish      F        Natick MA US   \n",
            "4     NaN  asian          chinese      F        Goshen MA US   \n",
            "\n",
            "                                        ADDRESS  \n",
            "0           661 Carole Park Eastham MA 02642 US  \n",
            "1         176 Corkery Walks Eastham MA 02642 US  \n",
            "2      98180 Dach Circle Barnstable MA 02630 US  \n",
            "3  11768 Ward Key Suite 834 Eastham MA 02642 US  \n",
            "4          9388 Maud Valleys Bourne MA 02559 US  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "             ID   BIRTHDATE DEATHDATE      SSN  DRIVERS PASSPORT   PREFIX  \\\n",
            "count   1594250     1594036    399139  1592981  1351991  1280926  1316503   \n",
            "unique  1593866       42307     30745   697762    91356   638743     1606   \n",
            "top       false  1954-10-21         M        M    false    false      Mr.   \n",
            "freq         78          89        78       62      139   639453   659289   \n",
            "\n",
            "          FIRST          LAST SUFFIX  MAIDEN  MARITAL     RACE ETHNICITY  \\\n",
            "count   1593010       1593105  18839  456395  1145292  1592942   1593048   \n",
            "unique    36843          6997   1330    6423      739      864       964   \n",
            "top         Mr.  Daugherty866    PhD       M        M    white     irish   \n",
            "freq        225           598   5724     224   914419  1227774    328857   \n",
            "\n",
            "         GENDER    BIRTHPLACE  ADDRESS  \n",
            "count   1592708       1592750  1592431  \n",
            "unique      744          1313  1591829  \n",
            "top           M  Boston MA US        M  \n",
            "freq     796782        149926      169  \n",
            "\n",
            "================================================================================\n",
            "File: conditions.csv\n",
            "================================================================================\n",
            "\n",
            "Dataset Info:\n",
            "Total Rows: 5,809,954\n",
            "Total Columns: 6\n",
            "\n",
            "Columns: START, STOP, PATIENT, ENCOUNTER, CODE, DESCRIPTION\n",
            "\n",
            "First 5 rows:\n",
            "        START        STOP                               PATIENT  \\\n",
            "0  1998-01-13         NaN  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "1  2012-12-22  2013-01-08  d4e6730a-7a34-46aa-96dd-6cdf3f2f7798   \n",
            "2  2010-05-28  2010-06-15  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "3  2013-03-28  2013-04-27  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "4  2013-08-27  2013-10-17  fef09c76-9855-4a56-a8a8-49085af31cd2   \n",
            "\n",
            "                              ENCOUNTER       CODE  \\\n",
            "0  e394c6e8-aec3-4764-becd-9f706d0a5c01   40055000   \n",
            "1  d626c050-ae52-4c54-90c8-860245026c93  444814009   \n",
            "2  dfa57629-b9a6-4e58-abde-cb6f71340c0e   43878008   \n",
            "3  1d8ae558-1659-4d68-8244-49d85103f7f6  444814009   \n",
            "4  fd34e314-bda3-4d0e-9cc2-e10c331757df   75498004   \n",
            "\n",
            "                            DESCRIPTION  \n",
            "0          Chronic sinusitis (disorder)  \n",
            "1            Viral sinusitis (disorder)  \n",
            "2  Streptococcal sore throat (disorder)  \n",
            "3            Viral sinusitis (disorder)  \n",
            "4  Acute bacterial sinusitis (disorder)  \n",
            "\n",
            "Numeric Columns Statistics:\n",
            "               CODE\n",
            "count  5.809954e+06\n",
            "mean   2.869376e+12\n",
            "std    2.967073e+13\n",
            "min    1.734006e+06\n",
            "25%    3.984801e+07\n",
            "50%    7.440001e+07\n",
            "75%    3.702470e+08\n",
            "max    3.685810e+14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.ZIP Archive Creation Code"
      ],
      "metadata": {
        "id": "S-MhWUfHxc1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "\n",
        "## Function Purpose\n",
        "The `create_zip_archive` function creates a ZIP file from the merged CSV data directory, making it easy to share or store the processed data.\n",
        "\n",
        "## Input Parameters\n",
        "- `source_dir`: Directory to be zipped (default: 'final_merge')\n",
        "- `zip_name`: Name for the output ZIP file (default: 'final_merge_data')\n",
        "\n",
        "## Process Flow\n",
        "1. **Path Setup**:\n",
        "   - Creates Path objects for source directory\n",
        "   - Sets up ZIP file destination path\n",
        "\n",
        "2. **Archive Creation**:\n",
        "   - Uses shutil.make_archive for compression\n",
        "   - Creates ZIP format archive\n",
        "   - Includes all files from source directory\n",
        "\n",
        "3. **Size Reporting**:\n",
        "   - Calculates final archive size\n",
        "   - Converts size to megabytes\n",
        "   - Displays formatted size\n",
        "\n",
        "## Error Handling\n",
        "- Catches potential compression errors\n",
        "- Provides error feedback\n",
        "- Ensures graceful failure handling\n",
        "\n",
        "## Output Information\n",
        "- Confirms successful archive creation\n",
        "- Shows final archive path\n",
        "- Reports compressed file size\n",
        "- Uses readable size format (MB)\n",
        "\n",
        "## Example Usage\n",
        "Shows how to create a ZIP archive named 'SyntheticMass_Data_Hack_ArangoDB' from the processed data."
      ],
      "metadata": {
        "id": "cFS8m37g0Q6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code"
      ],
      "metadata": {
        "id": "tZJMmQ8H1AHI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "def create_zip_archive(source_dir='final_merge', zip_name='final_merge_data'):\n",
        "    \"\"\"\n",
        "    Create a zip archive of the final_merge folder\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get full paths\n",
        "        source_path = Path(source_dir)\n",
        "        zip_path = Path(f\"{zip_name}.zip\")\n",
        "\n",
        "        # Create zip archive\n",
        "        print(f\"Creating zip archive of {source_dir}...\")\n",
        "        shutil.make_archive(zip_name, 'zip', source_path)\n",
        "\n",
        "        # Get zip file size\n",
        "        zip_size = zip_path.stat().st_size / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "        print(f\"\\nZip archive created successfully: {zip_path}\")\n",
        "        print(f\"Archive size: {zip_size:.2f} MB\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating zip archive: {str(e)}\")\n",
        "\n",
        "# Create the zip archive\n",
        "create_zip_archive(zip_name='SyntheticMass_Data_Hack_ArangoDB')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQxfjAJgebIS",
        "outputId": "3debad12-a2fc-44ad-9843-69a00b869154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating zip archive of final_merge...\n",
            "\n",
            "Zip archive created successfully: SyntheticMass_Data_Hack_ArangoDB.zip\n",
            "Archive size: 2303.02 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Hugging Face Dataset Upload Code\n"
      ],
      "metadata": {
        "id": "xxClBZxaxssa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Code Explanation**\n",
        "\n",
        "## Function Purpose\n",
        "This code uploads a processed dataset ZIP file to Hugging Face's dataset repository system.\n",
        "\n",
        "## Component Setup\n",
        "1. **Library Requirements**:\n",
        "   - Imports HfApi for Hugging Face interaction\n",
        "   - Uses getpass for secure token input\n",
        "\n",
        "2. **Authentication**:\n",
        "   - Securely prompts for Hugging Face token\n",
        "   - Initializes API with credentials\n",
        "\n",
        "## Upload Configuration\n",
        "- **Source File**: Local ZIP archive 'SyntheticMass_Data_Hack_ArangoDB.zip'\n",
        "- **Destination**: Specified repository path\n",
        "- **Repository Details**:\n",
        "  - ID: \"ajitonelson/synthetic-mass-health-data\"\n",
        "  - Type: Dataset repository\n",
        "  - File Path: Maintains original ZIP name\n",
        "\n",
        "## Upload Process\n",
        "1. Takes local ZIP file\n",
        "2. Authenticates with provided token\n",
        "3. Uploads to specified repository\n",
        "4. Maintains file structure\n",
        "5. Uses dataset-specific repository type\n",
        "\n",
        "## Security Features\n",
        "- Uses getpass for hidden token entry\n",
        "- Secures API communication\n",
        "- Maintains token privacy"
      ],
      "metadata": {
        "id": "AUVQZ1_sz_5D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CODE"
      ],
      "metadata": {
        "id": "9GRWJAG6z1w7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi\n",
        "from getpass import getpass\n",
        "\n",
        "# Get token\n",
        "hf_token = getpass('Enter your Hugging Face token: ')\n",
        "\n",
        "# Initialize API\n",
        "api = HfApi()\n",
        "\n",
        "# Upload files to existing repository\n",
        "api.upload_file(\n",
        "    path_or_fileobj=\"/content/SyntheticMass_Data_Hack_ArangoDB.zip\",\n",
        "    path_in_repo=\"SyntheticMass_Data_Hack_ArangoDB.zip\",\n",
        "    repo_id=\"ajitonelson/synthetic-mass-health-data\",\n",
        "    repo_type=\"dataset\",\n",
        "    token=hf_token\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "e2736a733f01423382a074eb3cb2ed9c",
            "4ced804aa41f48a4902c8290aea1ef24",
            "038d4d4e35b34509a8895ed99f8b7bbb",
            "cc7b5d15ceec4c389cfa4fe717f13e0d",
            "fc1a9405b52b48f6995badd9d9524386",
            "286395902e104061b386ea16c283b1ee",
            "ed4a51a2c1e84d48aac72998ec87a159",
            "49fa3062c18644bf94faf5c422086176",
            "b573c07b35544b2e82fd22a2f4595b48",
            "da6901289f7b463d8db19c805b7d205c",
            "1ffcf384751648819d22fd82929ef310"
          ]
        },
        "id": "BvzFpEuypHPC",
        "outputId": "c47d3b52-dac5-4b92-a9bc-bb9f226eed58"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Hugging Face token: Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "SyntheticMass_Data_Hack_ArangoDB.zip:   0%|          | 0.00/2.41G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2736a733f01423382a074eb3cb2ed9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/datasets/ajitonelson/synthetic-mass-health-data/commit/ae5eff0194827991afd72e9075fe18310fa7acfe', commit_message='Upload SyntheticMass_Data_Hack_ArangoDB.zip with huggingface_hub', commit_description='', oid='ae5eff0194827991afd72e9075fe18310fa7acfe', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ajitonelson/synthetic-mass-health-data', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ajitonelson/synthetic-mass-health-data'), pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "\n",
        "# ðŸ“š Access the Dataset\n",
        "\n",
        "Visit Hugging Face to explore and download the Synthetic Mass Health Dataset:  \n",
        "[ajitonelson/synthetic-mass-health-data](https://huggingface.co/datasets/ajitonelson/synthetic-mass-health-data)\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“‹ Dataset Overview\n",
        "- Full synthetic patient health records\n",
        "- Multiple CSV files with related health data\n",
        "- Processed and merged for easy analysis\n",
        "- Available as a compressed ZIP archive\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ¤ Contributing\n",
        "Feel free to open issues or submit pull requests to improve the dataset.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“„ License\n",
        "This dataset is available under standard Synthea licensing terms.\n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ™ Acknowledgments\n",
        "- Syntheaâ„¢ Project for synthetic data generation\n",
        "- Hugging Face for dataset infrastructure\n",
        "\n",
        "---\n",
        "\n",
        "*Made with* â¤ï¸ *in Timor-Leste*\n",
        "\n",
        "*Â© 2025 All rights reserved*"
      ],
      "metadata": {
        "id": "ClbsQ61tyHrm"
      }
    }
  ]
}